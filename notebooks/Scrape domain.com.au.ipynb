{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup (url):\n",
    "    '''Fetch HTML of the page and parse HTML\n",
    "    Return the parsed HTML'''\n",
    "    headers = requests.utils.default_headers()\n",
    "\n",
    "    headers.update(\n",
    "        {\n",
    "            'User-Agent': 'My User Agent 1.0',\n",
    "        }\n",
    "    )\n",
    "\n",
    "    page = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "    return soup\n",
    "\n",
    "def get_price (property):\n",
    "    '''Find the rental price of the property'''\n",
    "    price_tag = property.find('p', class_='css-mgq8yx', attrs={'data-testid': 'listing-card-price'})\n",
    "\n",
    "    # Extract the text content of the <p> tag\n",
    "    price_text = price_tag.text\n",
    "\n",
    "    # Use a regular expression to extract the numeric value from the price text\n",
    "    price_match = re.search(r'\\$\\d[\\d,]*\\.?\\d*', price_text)\n",
    "    \n",
    "    if price_match:\n",
    "        price_number = price_match.group().replace('$', '').replace(',', '')\n",
    "        return price_number\n",
    "    else: \n",
    "        return None\n",
    "    \n",
    "def get_suburb (property):\n",
    "    '''Find the suburb and postcode of the property'''\n",
    "    address_line2 = property.find('span', {'data-testid': 'address-line2'})\n",
    "    address_details = address_line2.find_all('span')\n",
    "\n",
    "    if len(address_details) >= 3:\n",
    "        suburb = address_details[0].text.strip()\n",
    "        postcode = address_details[2].text.strip()\n",
    "\n",
    "    return suburb, postcode\n",
    "\n",
    "def standardize_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove the plural 's' (if any) at the end of the word\n",
    "    text = re.sub(r's$', '', text)\n",
    "    return text\n",
    "\n",
    "def get_features (property):\n",
    "    # Initialize variables for bedrooms and bathrooms\n",
    "    bedrooms = None\n",
    "    bathrooms = None\n",
    "    parkings = None\n",
    "\n",
    "    # Extract bedrooms and bathrooms\n",
    "    property_features = property.find_all('span', {'data-testid': 'property-features-text-container'})\n",
    "    \n",
    "    for feature in property_features:\n",
    "        number = feature.contents[0].strip()\n",
    "        if number == 'âˆ’':\n",
    "            number = 0\n",
    "\n",
    "        label_tag = feature.find('span', {'data-testid': 'property-features-text'})\n",
    "        if label_tag:\n",
    "            label = label_tag.text.strip()\n",
    "            label = standardize_text(label)\n",
    "        else: continue\n",
    "\n",
    "        if label == 'bed':\n",
    "            bedrooms = number\n",
    "        elif label == 'bath':\n",
    "            bathrooms = number\n",
    "        elif label == 'parking':\n",
    "            parkings = number\n",
    "\n",
    "    return bedrooms, bathrooms, parkings\n",
    "\n",
    "def get_next_url (soup):\n",
    "    page_link_tag = soup.find_all('a', {'data-testid': 'paginator-navigation-button'})\n",
    "    for link_tag in page_link_tag:\n",
    "        page_label_tag = link_tag.find('span', class_='css-16q9xmc')\n",
    "        page_label = page_label_tag.text\n",
    "        if page_label == 'prev page':\n",
    "            continue  \n",
    "        elif page_label == 'next page':\n",
    "            url = \"https://www.domain.com.au\" + link_tag['href']\n",
    "            return url\n",
    "        else:\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.domain.com.au/rent/vic/\"\n",
    "properties = []\n",
    "count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "while url:\n",
    "    print(count)\n",
    "    soup = get_soup(url)\n",
    "    listings = soup.find_all('div', {'class': 'css-qrqvvg'})\n",
    "    for property in listings:\n",
    "        price = get_price(property)\n",
    "        if not price:\n",
    "            continue\n",
    "        suburb, postcode = get_suburb(property)\n",
    "        bedrooms, bathrooms, parkings = get_features(property)\n",
    "        property_type = property.find('span', class_='css-693528').text.strip()\n",
    "\n",
    "        # Store the extracted data in a dictionary\n",
    "        property_data = {\n",
    "            'price (AUD per week)': price,\n",
    "            'bedrooms': bedrooms,\n",
    "            'bathrooms': bathrooms,\n",
    "            'parkings': parkings,\n",
    "            'property type': property_type,\n",
    "            'suburb': suburb,\n",
    "            'postcode': postcode\n",
    "        }\n",
    "\n",
    "        # Append the dictionary to the list of properties\n",
    "        properties.append(property_data)\n",
    "    url = get_next_url(soup)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to properties.csv\n"
     ]
    }
   ],
   "source": [
    "# Convert list of dictionaries to a pandas DataFrame\n",
    "df = pd.DataFrame(properties)\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv('properties.csv', index=False)\n",
    "\n",
    "print('Data successfully written to properties.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_df = pd.read_csv('properties.csv')\n",
    "mean_price_per_postcode = property_df.groupby('postcode')['price (AUD per week)'].mean()\n",
    "mean_price_df = mean_price_per_postcode.reset_index()\n",
    "# Save the DataFrame to a CSV file\n",
    "mean_price_df.to_csv('mean_price_per_postcode.csv', index=False)\n",
    "\n",
    "print(\"File saved successfully as 'mean_price_per_postcode.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
