{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import folium\n",
    "from ipyleaflet import GeoJSON, Map, Marker\n",
    "import geopandas as gpd\n",
    "import geojson\n",
    "import statsmodels\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "import openrouteservice\n",
    "from pmdarima import auto_arima \n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier, RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Download Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../scripts/download.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "%run ../notebooks/Data_preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert property address to coorinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../scripts/'address_coordinate_converter.py'\n",
    "\n",
    "# Utilizing Open Route Service API, takes about 30 minutes to complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the distance to the nearest train station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../scripts/'property_train_euclidean_distance.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Question 1 (Important Features for Predicting Rental Price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our classification model, the four most important features for predicting rental prices are as follows:\n",
    "\n",
    "\n",
    "1. Bedrooms: The number of bedrooms is a significant determinant of rental prices, as it directly correlates with the capacity and comfort of the living space. \n",
    "Properties with more bedrooms typically cater to larger households, making them more desirable and, consequently, commanding higher rental rates.\n",
    "\n",
    "\n",
    "2. Postcode: The postcode serves as an indicator of the property's location, which significantly influences rental values. \n",
    "Areas with desirable postcodes often offer better access to amenities, transportation, and schools, \n",
    "contributing to higher demand and increased rental prices.\n",
    "\n",
    "\n",
    "3. Bathrooms: The quantity of bathrooms is another crucial factor impacting rental pricing.\n",
    "A higher number of bathrooms enhances convenience for tenants, \n",
    "especially in larger households, and is often seen as a desirable feature that can justify a premium in rental costs.\n",
    "\n",
    "\n",
    "4. Parking Spaces: The availability of parking spaces is a vital consideration in many regions, \n",
    "particularly in urban settings where parking can be scarce. \n",
    "Properties that offer designated parking tend to attract tenants who prioritize this convenience, \n",
    "thereby increasing the potential rental value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "property_df = pd.read_csv(\"../data/curated/processed property_w_distance.csv\")\n",
    "property_df['log_min_train_dist'] = np.log1p(property_df['min_train_dist'])\n",
    "corr_columns = [\n",
    "    \"price (AUD per week)\", \"bedrooms\", \"bathrooms\", \"parkings\", \"log_min_train_dist\"\n",
    "]\n",
    "\n",
    "sns.heatmap(property_df[corr_columns].corr())\n",
    "\n",
    "plt.title('Pearson Correlation Metric')\n",
    "plt.savefig('../plots/pearson_corr.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "# no strong relationship bewteen price and log_min_train_dist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Spearman's correlation, bedroom number is still the most significant.\\\n",
    "The correlation is almost zero between distance to the closest train station and rental price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(property_df[corr_columns].corr(method='spearman'))\n",
    "plt.title('Spearman Correlation Metric')\n",
    "plt.savefig('../plots/spearmans_corr.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# still no strong relationship bewteen price and log_min_train_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using Anova, there are sufficent evidences to the effect of suburb and property type on rental price.\n",
    "Suburb have a 0.000172 p-vlaue, and property type have the p-value equal to 1.878596e-41."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "# Rename the 'price (AUD per week)' column\n",
    "property_df = property_df.rename(columns={'price (AUD per week)': 'price_per_week'})\n",
    "# Rename the 'property type' column\n",
    "property_df = property_df.rename(columns={'property type': 'property_type'})\n",
    "\n",
    "# test effect of suburb on rental price\n",
    "model_suburb = ols('price_per_week ~ C(suburb)', data=property_df).fit()\n",
    "\n",
    "anova_suburb = sm.stats.anova_lm(model_suburb, typ=2)\n",
    "print(anova_suburb)\n",
    "\n",
    "# there is a statistically significant effect of suburb on rental price\n",
    "\n",
    "# test effect of property type on rental price\n",
    "model_type = ols('price_per_week ~ C(property_type)', data=property_df).fit()\n",
    "\n",
    "anova_type = sm.stats.anova_lm(model_type, typ=2)\n",
    "print(anova_type)\n",
    "\n",
    "# there is a statistically significant effect of property type on rental price\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We developed classification models to predict rental price categories. Our best-performing models were Random Forest and Gradient Boosting, both achieving an accuracy of 77%. This high accuracy rate supports the reliability of our feature importance analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification models provided additional insights into feature importance. They confirmed that the number of bedrooms and bathrooms are indeed crucial factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('../data/curated/processed property_w_distance.csv')\n",
    "\n",
    "\n",
    "# Clean and preprocess the data\n",
    "data['price'] = data['price (AUD per week)']\n",
    "data['log_rental_price'] = np.log(data['price'])\n",
    "data['bedrooms'] = data['bedrooms'].fillna(0)\n",
    "\n",
    "# Create price categories for classification\n",
    "data['price_category'] = pd.cut(data['price per bedroom'], bins=[0, 300, 600, 900, np.inf],\n",
    "                                labels=['Low', 'Medium', 'High', 'Very High'])\n",
    "\n",
    "# Split features and target\n",
    "X = data[['bedrooms', 'bathrooms', 'parkings', 'property type', 'suburb', 'min_train_dist']]\n",
    "y_regression = data['log_rental_price']\n",
    "y_classification = data['price_category']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_reg_train, y_reg_test, y_class_train, y_class_test = train_test_split(\n",
    "    X, y_regression, y_classification, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create preprocessor\n",
    "numeric_features = ['bedrooms', 'bathrooms', 'parkings', 'min_train_dist']\n",
    "categorical_features = ['property type', 'suburb']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Regression Model\n",
    "reg_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "reg_model.fit(X_train, y_reg_train)\n",
    "y_reg_pred = reg_model.predict(X_test)\n",
    "\n",
    "# Classification Model\n",
    "class_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "class_model.fit(X_train, y_class_train)\n",
    "y_class_pred = class_model.predict(X_test)\n",
    "\n",
    "# Visualization 1: Regression Model - Predicted vs Actual\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_reg_test, y_reg_pred, alpha=0.5)\n",
    "plt.plot([y_reg_test.min(), y_reg_test.max()], [y_reg_test.min(), y_reg_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.title('Regression Model: Predicted vs Actual Prices')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualization 2: Regression Model - Residuals Plot\n",
    "residuals = y_reg_test - y_reg_pred\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_reg_pred, residuals, alpha=0.5)\n",
    "plt.hlines(y=0, xmin=y_reg_pred.min(), xmax=y_reg_pred.max(), colors='r', linestyles='--')\n",
    "plt.xlabel('Predicted Price')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Regression Model: Residuals Plot')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualization 3: Classification Model - Confusion Matrix\n",
    "cm = confusion_matrix(y_class_test, y_class_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Classification Model: Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualization 4: Classification Model - Feature Importance\n",
    "feature_importance = class_model.named_steps['classifier'].feature_importances_\n",
    "feature_names = (numeric_features +\n",
    "                 class_model.named_steps['preprocessor']\n",
    "                 .named_transformers_['cat']\n",
    "                 .get_feature_names_out(categorical_features).tolist())\n",
    "\n",
    "feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': feature_importance})\n",
    "feature_importance_df = feature_importance_df.sort_values('importance', ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance_df)\n",
    "plt.title('Classification Model: Top 10 Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print model performance metrics\n",
    "print(\"Regression Model Performance:\")\n",
    "print(f\"Mean Squared Error: {mean_squared_error(y_reg_test, y_reg_pred):.2f}\")\n",
    "print(f\"R-squared Score: {r2_score(y_reg_test, y_reg_pred):.2f}\")\n",
    "\n",
    "print(\"\\nClassification Model Performance:\")\n",
    "print(f\"Accuracy: {class_model.score(X_test, y_class_test):.2f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_class_test, y_class_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train new models\n",
    "simple_reg_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', DecisionTreeRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "simple_class_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "complex_reg_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', GradientBoostingRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "complex_class_model = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Fit the models\n",
    "simple_reg_model.fit(X_train, y_reg_train)\n",
    "complex_reg_model.fit(X_train, y_reg_train)\n",
    "simple_class_model.fit(X_train, y_class_train)\n",
    "complex_class_model.fit(X_train, y_class_train)\n",
    "\n",
    "# Predictions\n",
    "y_simple_reg_pred = simple_reg_model.predict(X_test)\n",
    "y_complex_reg_pred = complex_reg_model.predict(X_test)\n",
    "y_simple_class_pred = simple_class_model.predict(X_test)\n",
    "y_complex_class_pred = complex_class_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "# Regression Model Performance (Simple and Complex)\n",
    "simple_reg_mse = mean_squared_error(y_reg_test, y_simple_reg_pred)\n",
    "simple_reg_r2 = r2_score(y_reg_test, y_simple_reg_pred)\n",
    "\n",
    "complex_reg_mse = mean_squared_error(y_reg_test, y_complex_reg_pred)\n",
    "complex_reg_r2 = r2_score(y_reg_test, y_complex_reg_pred)\n",
    "\n",
    "# Classification Model Performance (Simple and Complex)\n",
    "simple_class_report = classification_report(y_class_test, y_simple_class_pred, output_dict=True)\n",
    "complex_class_report = classification_report(y_class_test, y_complex_class_pred, output_dict=True)\n",
    "\n",
    "# Prepare the comparison table for regression\n",
    "regression_comparison = pd.DataFrame({\n",
    "    'Model': ['Linear Regression', 'Decision Tree', 'Gradient Boosting'],\n",
    "    'MSE': [mean_squared_error(y_reg_test, y_reg_pred), simple_reg_mse, complex_reg_mse],\n",
    "    'R-squared': [r2_score(y_reg_test, y_reg_pred), simple_reg_r2, complex_reg_r2]\n",
    "})\n",
    "\n",
    "# Prepare the comparison table for classification\n",
    "classification_comparison = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'Decision Tree', 'Gradient Boosting'],\n",
    "    'Accuracy': [class_model.score(X_test, y_class_test), simple_class_model.score(X_test, y_class_test), complex_class_model.score(X_test, y_class_test)],\n",
    "    'Precision (Weighted Avg)': [simple_class_report['weighted avg']['precision'], simple_class_report['weighted avg']['precision'], complex_class_report['weighted avg']['precision']],\n",
    "    'Recall (Weighted Avg)': [simple_class_report['weighted avg']['recall'], simple_class_report['weighted avg']['recall'], complex_class_report['weighted avg']['recall']]\n",
    "})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the regression model comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"Model\", y=\"MSE\", data=regression_comparison, hue=\"Model\")\n",
    "plt.title(\"Regression Model Comparison (MSE)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"Model\", y=\"R-squared\", data=regression_comparison, hue=\"Model\")\n",
    "plt.title(\"Regression Model Comparison (R-squared)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plotting the classification model comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"Model\", y=\"Accuracy\", data=classification_comparison, hue=\"Model\")\n",
    "plt.title(\"Classification Model Comparison (Accuracy)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"Model\", y=\"Precision (Weighted Avg)\", data=classification_comparison, hue=\"Model\")\n",
    "plt.title(\"Classification Model Comparison (Precision - Weighted Avg)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=\"Model\", y=\"Recall (Weighted Avg)\", data=classification_comparison, hue=\"Model\")\n",
    "plt.title(\"Classification Model Comparison (Recall - Weighted Avg)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Question 2 (Predict Suburb Growth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the ARIMA models to the historical data\n",
    "%run ../models/'ARIMA model.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting the ARIMA model to the historical rental price and predict the future prices, we have output the predictions dataframe as below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these predictions, we can calculate the annual growth rate and output the top 10 suburbs with the highest growth rate for each property type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also evaluate our ARIMA model using time-series cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the historical and predictions data\n",
    "historical_df = pd.read_csv('../data/curated/historical without postcode/cleaned All properties.csv')\n",
    "predict_df = pd.read_csv('../data/analysis/future prices by suburb/predict all properties.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date in df to datetime format\n",
    "historical_df.set_index('suburb', inplace=True)\n",
    "predict_df.set_index('index', inplace=True)\n",
    "historical_df.columns = pd.to_datetime(historical_df.columns, format='%b %Y')\n",
    "predict_df.index = pd.to_datetime(predict_df.index, dayfirst=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will visualise the rental price predictions of one of the suburbs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first suburb name\n",
    "first_suburb = historical_df.index[0]\n",
    "\n",
    "# Plot historical prices for the first suburb\n",
    "plt.plot(historical_df.columns, historical_df.loc[first_suburb], label=f'Historical {first_suburb}', color='blue')\n",
    "\n",
    "# Plot predicted prices for the same suburb\n",
    "plt.plot(predict_df.index, predict_df[first_suburb], label=f'Predicted {first_suburb}', color='orange', linestyle='--')\n",
    "\n",
    "# Format the x-axis\n",
    "ax = plt.gca()  \n",
    "ax.xaxis.set_major_locator(mdates.AutoDateLocator()) \n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.title(f'Median Rental Prices for {first_suburb}')\n",
    "plt.ylabel('Median Rental Price (AUD per week)')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot is saved under ..plots/future predictions of one suburb.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trend in the predicted values is similar to the trend of rental prices pre-COVID, suggesting that our model is not significantly affected by the data drift during COVID."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the calculated growth rate, we can see the top 10 suburbs with highest predicted growth rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '../data/analysis/future prices by suburb/'\n",
    "growth_filename = ['growth 1 bedroom flat.csv', 'growth 2 bedroom flat.csv', 'growth 3 bedroom flat.csv',\n",
    "                    'growth 2 bedroom house.csv', 'growth 3 bedroom house.csv', 'growth 4 bedroom house.csv',\n",
    "                    'growth all properties.csv']\n",
    "\n",
    "property_types = ['one bed flat', 'two bed flat', 'three bed flat', 'two bed house', 'three bed house',\n",
    "                 'four bed house', 'all properties']\n",
    "\n",
    "for i in range(len(growth_filename)):\n",
    "    file_path = folder_path + growth_filename[i]\n",
    "    growth_df = pd.read_csv(file_path)\n",
    "    top_10 = growth_df.nlargest(10, 'growth rate')\n",
    "    property_type = property_types[i]\n",
    "    print(f\"Top 10 suburbs with highest predicted growth rate for {property_type}\")\n",
    "    print(top_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will evaluate the performance of ARIMA models by calculating the time-series cross-validation's RMSE for the all properties type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TimeSeriesSplit with 5 splits\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "rmse_scores = []\n",
    "\n",
    "for suburb in historical_df.index:  \n",
    "    rental_prices = historical_df.loc[suburb].dropna() \n",
    "\n",
    "    # Perform TimeSeriesSplit cross-validation\n",
    "    for train_index, test_index in tscv.split(rental_prices):\n",
    "        y_train, y_test = rental_prices[train_index], rental_prices[test_index]\n",
    "\n",
    "        # Fit ARIMA model on the training set\n",
    "        model = auto_arima(y_train, seasonal=False, stepwise=True)\n",
    "\n",
    "        # Forecast the same number of periods as the test set\n",
    "        forecast = model.predict(n_periods=len(y_test))\n",
    "\n",
    "        # Calculate RMSE for this fold\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, forecast))\n",
    "        rmse_scores.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print average RMSE across all splits\n",
    "print(f'Average RMSE: ${np.mean(rmse_scores):.2f} per week')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the average RMSE calculated from time-series cross-validation on the historical data, therefore it is influenced by the deviations from predictions during COVID-19. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would expect smaller RMSE for our predictions if no future data drift occurs, or similar RMSE if there is an occurence of some data drift of the scale of COVID-19."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Question 3 (Liveability and Afforfability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liveability as a feature of a region is difficult to quantify, however with the use of the Social Indicators dataset from the City of Melbourne public population census data we can compose an aggregated statistic which captures information about aspects of liveability such as: health, quality of life, engagement with learning, and how safe people feel. The drawback to this dataset is the fairly limited coverage across our suburbs of interest, and less than total coverage of the City of Melbourne postcodes. This leads to some data sparsity, however we can still draw some meaningful conclusions from the analysis of this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Liveability = w_h \\cdot \\frac{1}{n} \\sum_{i=1}^{n}h_i + w_q \\cdot \\frac{1}{n} \\sum_{i=1}^{n}q_i + w_l \\cdot \\frac{1}{n} \\sum_{i=1}^{n}l_i + w_s \\cdot \\frac{1}{n} \\sum_{i=1}^{n}s_i$\n",
    "\n",
    "$w_h$ = weighting for health scores, $h_i$ = ith health score\n",
    "\n",
    "$w_q$ = weighting for quality of life scores, $q_i$ = ith quality of life score\n",
    "\n",
    "$w_l$ = weighting for learning scores, $l_i$ = ith learning score\n",
    "\n",
    "$w_s$ = weighting for safety scores, $s_i$ = ith safety score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "liveability_df = pd.read_csv(\"../data/curated/liveability_scores.csv\").set_index(\"postcode\")\n",
    "liveability_melted_df = liveability_df.reset_index().melt(id_vars=['suburb', 'postcode'])\n",
    "\n",
    "def CalculateWeightedLiveabilityScore(dataframe, weights = [1,1,1,1,1,1,1]):\n",
    "    return sum([dataframe[dataframe.columns[x]] * weights[x] for x in range(0, len(dataframe.columns) - 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liveability scores and individual metrics for suburbs with available social indicator data from highest score to lowest\n",
    "liveability_df.sort_values(by=[\"score\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above table we can see Flemington has the highest score given equal weightings for the three metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot liveability scores across surveyed suburbs\n",
    "c_plot = sns.catplot(data = liveability_melted_df, x = \"suburb\", y = \"value\", hue = \"variable\")\n",
    "c_plot.set_xticklabels(rotation = 45, ha='right')\n",
    "c_plot.set(title=\"City of Melbourne Suburbs: Liveability Score and Composit Metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Geospatial Visualisations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Geojson postcode boundaries from the City of Melbourne public data repository we can plot some of the features and statistics we've calculated over the course of the analysis on maps as geospatial visualisations. Some notable features to look at in this format are median rental prices, and liveability scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_postcode_df = pd.read_csv(\"../data/raw/median_price_per_postcode.csv\")\n",
    "historical_price_df = pd.read_csv(\"../data/raw/cleaned all properties.csv\")\n",
    "\n",
    "with open(\"../data/landing/geodata/suburbs.geojson\", \"r\") as f:\n",
    "    geojson_suburbs = geojson.load(f)\n",
    "\n",
    "# define colouring function for median rental price\n",
    "def median_rental_colour(feature):\n",
    "    postcode = feature[\"properties\"][\"mccid_int\"]\n",
    "    df_median_price = median_postcode_df[median_postcode_df[\"postcode\"] == int(postcode)]\n",
    "    if df_median_price.empty:\n",
    "        return {\"color\":\"white\", \"fillColor\":\"black\"}   \n",
    "    median_price_max = max(median_postcode_df[\"median_1_bedroom_Apartment / Unit / Flat\"])\n",
    "    median_price_min = min(median_postcode_df[\"median_1_bedroom_Apartment / Unit / Flat\"])\n",
    "    price_col = (df_median_price[\"median_1_bedroom_Apartment / Unit / Flat\"] - median_price_min) / (median_price_max - median_price_min)\n",
    "    hex_col = colors.to_hex(cm.YlOrRd(float(max(price_col)))) \n",
    "    return {\"color\":\"white\", \"fillColor\":hex_col}\n",
    "\n",
    "# define colouring function for liveability score\n",
    "def liveability_colour(feature):\n",
    "    postcode = int(feature[\"properties\"][\"mccid_int\"])\n",
    "    if not postcode in liveability_df.index:\n",
    "        return {\"color\":\"white\", \"fillColor\":\"black\"}\n",
    "    score_col = liveability_df.loc[postcode].score\n",
    "    hex_col = colors.to_hex(cm.RdYlGn(score_col/7.0)) \n",
    "    return {\"color\":\"white\", \"fillColor\":hex_col}\n",
    "\n",
    "# construct map given a colouring\n",
    "def map(map_func):\n",
    "    map_melb = Map(center=(-37.8082, 144.96332), zoom=12)\n",
    "    geo_json = GeoJSON(  \n",
    "        data=geojson_suburbs,  \n",
    "        style={  \n",
    "            \"opacity\": 1,  \n",
    "            \"dashArray\": \"9\",  \n",
    "            \"fillOpacity\": 0.5,  \n",
    "            \"weight\": 1,  \n",
    "        },\n",
    "        hover_style={\"color\": \"white\", \"dashArray\": \"0\", \"fillOpacity\": 0.8},\n",
    "        style_callback = map_func\n",
    "    ) \n",
    "    map_melb.add_layer(geo_json)\n",
    "    \n",
    "    return map_melb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map of The City of Melbourne with postcodes shaded by median rent price for 1 bedroom appartments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display median rental price map\n",
    "map(median_rental_colour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in the CBD the weekly rent price of 1 bedroom appartments is significantly higher than areas further towards the edges of the city suggesting that this is likely to be a less affordable location for students to rent in if they're living alone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map of The City of Melbourne with postcodes shaded by liveability score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display liveabiltiy map\n",
    "map(liveability_colour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to being unaffordable to rent, the CBD also has the lowest liveability score of all City of Melbourne postcodes whereas Flemington is both more affordable and has a high liveability score. Flemington isn't particularly close to any universities though so Carlton or East Melbourne may be more useful recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Limitations and Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data Acquisition: \n",
    "    - Rate Limiting with services like Openrouteservice makes transport based distance calculations time consuming so we had to compromise with euclidean distance.\n",
    "    - Social Indicator dataset restricted to a small number of surveyed postcodes\n",
    "- Model Limitations: \n",
    "    - Potential inaccuracies due to unanticipated socio-economic changes, like policy shifts affecting rental markets. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# liveability postcodes surveyed only span a small range of suburbs:\n",
    "liveability_df.sort_values(by=[\"score\"], ascending=False)[[\"suburb\", \"score\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Rental Data Dashboard App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the dashboard app run the following command:\n",
    "\n",
    "`shiny run --reload --launch-browser ../scripts/app.py`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mast30034_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
